import requests
from bs4 import BeautifulSoup
import time

def get_truist_10k_income_statement():
    cik = "0000092230"  # Truist Financial Corporation CIK
    base_url = "https://www.sec.gov"

    # Search for 10-K filings
    search_url = f"{base_url}/cgi-bin/browse-edgar?CIK={cik}&action=getcompany&type=10-K"
    headers = {
        "User-Agent": "FinanceNotebooksBot/1.0 (Contact: your_email@example.com)",
        "Accept-Language": "en-US,en;q=0.9",
    }

    try:
        response = requests.get(search_url, headers=headers)
        if response.status_code != 200:
            print(f"Failed to fetch the search page. HTTP Status: {response.status_code}")
            return
    except requests.RequestException as e:
        print(f"An error occurred while making the request: {e}")
        return

    soup = BeautifulSoup(response.content, "html.parser")

    # Find the first 10-K filing link
    filing_table = soup.find("table", class_="tableFile2")
    if not filing_table:
        print("Could not find the filing table.")
        return

    rows = filing_table.find_all("tr")
    filing_url = None
    for row in rows:
        cols = row.find_all("td")
        if len(cols) < 2:
            continue
        filing_type = cols[0].text.strip().lower()
        if "10-k" in filing_type:
            filing_link = cols[1].find("a")["href"]
            filing_url = f"{base_url}{filing_link}"
            break

    if not filing_url:
        print("Could not find a 10-K filing.")
        return

    # Introduce a short delay
    time.sleep(1)

    # Access the 10-K filing page
    try:
        filing_response = requests.get(filing_url, headers=headers)
        if filing_response.status_code != 200:
            print(f"Failed to fetch the 10-K filing page. HTTP Status: {filing_response.status_code}")
            return
    except requests.RequestException as e:
        print(f"An error occurred while accessing the filing page: {e}")
        return

    filing_soup = BeautifulSoup(filing_response.content, "html.parser")

    # Find the link to the HTML filing
    document_table = filing_soup.find("table", class_="tableFile", summary="Document Format Files")
    if not document_table:
        print("Could not find the document table.")
        return

    document_rows = document_table.find_all("tr")
    document_url = None
    for document_row in document_rows:
        cols = document_row.find_all("td")
        if len(cols) < 3:
            continue
        document_type = cols[3].text.strip().lower()
        if "10-k" in document_type:
            document_link = cols[2].find("a")["href"]
            document_url = f"{base_url}{document_link}"
            break

    if not document_url:
        print("Could not find the 10-K document.")
        return

    # Introduce another short delay
    time.sleep(1)

    # Access the HTML filing
    try:
        document_response = requests.get(document_url, headers=headers)
        if document_response.status_code != 200:
            print(f"Failed to fetch the 10-K document. HTTP Status: {document_response.status_code}")
            return
    except requests.RequestException as e:
        print(f"An error occurred while accessing the 10-K document: {e}")
        return

    document_soup = BeautifulSoup(document_response.content, "html.parser")

    # Extract the consolidated income statement
    # Search for specific keywords to locate the income statement table
    tables = document_soup.find_all("table")
    for table in tables:
        if table.find(string=lambda text: text and "Consolidated Income Statement" in text):
            print("Income statement found!")
            print(table.prettify())
            return

    print("Could not find the income statement.")

# Run the function
if __name__ == "__main__":
    get_truist_10k_income_statement()